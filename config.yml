# train configuration
train:
    # data directory containing input.txt
    data_dir: !!str data/weight-loss

    # size of RNN hidden state
    rnn_size: !!int 1024

    # number of layers in the RNN
    num_layers: !!int 2

    # rnn, gru, or lstm
    model: !!str lstm

    # minibatch size
    batch_size: !!int 256

    # RNN sequence length
    seq_length: !!int 25

    # number of epochs
    num_epochs: !!int 1

    # directory containing tensorboard logs
    log_dir: !!str logs

    # directory to store checkpointed models
    save_dir: !!str save

    # save frequency
    save_every: !!int 1000

    # clip gradients at this value
    grad_clip: !!float 5

    # learning rate
    learning_rate: !!float 0.002

    # decay rate for rmsprop
    decay_rate: !!float 0.97

    # % of gpu memory to be allocated to this process
    gpu_mem: !!float 1

    # continue training from saved model at this path. Path must contain files
    # saved by previous training process:
    #     'config.pkl'        : configuration;
    #     'words_vocab.pkl'   : vocabulary definitions;
    #     'checkpoint'        : paths to model file(s) (created by tf).
    #                             Note: this file contains absolute paths,
    #                             be careful when moving files around;
    #     'model.ckpt-*'      : file(s) with model definition (created by tf)
    init_from: null

    # character encoding of input.txt
    # from https://docs.python.org/3/library/codecs.html#standard-encodings
    input_encoding: null

sample:
    # model directory to load stored checkpointed models from
    save_dir: !!str save

    # number of words to sample
    sample_generated: !!int 200

    # prime text
    prime: !!str ' '

    # 1 = weighted pick, 2 = beam search pick
    pick: !!int 1

    # width of the beam search
    width: !!int 4

    # 0 to use max at each timestep,
    # 1 to sample at each timestep,
    # 2 to sample on spaces
    sample: !!int 1
